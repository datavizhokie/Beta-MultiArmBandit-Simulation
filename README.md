# Beta-MultiArmBandit-Simulation
 
This code simualtes consumer responses to multi-choice situations. Thompson Sampling is used to pull samples from each arm's Beta Distribution. The max theta gives a reward to the corresponding arm. Bayesian updates are then applied to each bandit distribution. The learning model eventually produces a winning arm over the specified event space.
